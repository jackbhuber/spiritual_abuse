# Methods {.unnumbered}

## Item Pool Development

@KochEdstrom2022 developed an initial pool of items to measure spiritual harm and abuse. The authors validated the construct of spiritual harm and abuse through literature review [@Kvarfordt-2010; @Nobakht-2017; @Oakley-2014; @Rodríguez-Carballeira-2015; @Swindle-2017; @Ward-2011; @Winell-nd] and interviews with survivors of religious and spiritual abuse. These interviews revealed an array of specific examples of potential abuse not described in the published literature such as abuse inflicted by narcissistic persons, financial coercion, developmentally inappropriate children's teachings, pressure to stay in physically abusive marriages, neglect of needed medical care, sexual discrimination, and shunning/shaming, among others. The authors generated items by drawing from publicly available measures of similar constructs and by writing new items to maximize construct coverage. Each item they adapted to measure either a potentially spiritually abusive event (inflicting emotional abuse by a religious leader or group and/or with a religious or spiritual component, usually involving coercion or control) or a theorized effect of spiritual abuse, based on the reports of self-described survivors of spiritual abuse in the qualitative literature. In developing items, the authors sought to balance construct coverage with alternate wording and efficiency for participants. They wanted to cover as much of the domain as possible in a survey that could be completed in 15 minutes.

## Participants and Procedures

Participants in the initial SHAS validation study were adults who responded to an online survey. To qualify for the survey, participants had to be at least 18 years of age and to have identified themselves as Christian in the past [@KochEdstrom2022].

The second author used snowball sampling to recruit participants to the study. He promoted the survey through various podcast feeds (in audio form during a podcast episode), e-mail lists, Facebook groups, and other online groups associated with progressive Christian podcasts based in the United States. Listeners/readers were encouraged to invite others who satisfied the criteria to take part in the survey. The second author also posted the link on his own social media accounts with a similar encouragement to invite others who satisfied the study criteria. The sampling priority was to reach the largest, most inclusive, community sample. Participants were consented before beginning the survey. The study was approved by the IRB at Northwest University. Data collection began on January 28, 2021 and concluded on February 27, 2021.

## Measures

### Demographics

Demographic variables included age, gender, race, and sexual orientation.

### Religious Background Characteristics

The questionnaire included several items asking about religious matters. These included items asking whether the respondent was raised in a Christian home, denomination (and demographics of membership and leadership) in which the respondent experienced abuse, current weekly consumption of progressive Christian podcast episodes, current religious identification, current theological identification, and current view of the Bible.

### Spiritual Harm and Abuse Items

The final survey instrument included a total of 66 prompts separated into two distinct categories [@KochEdstrom2022]. The first section, External Events, included 52 prompts about potentially abusive experiences. Prompts in this section measured prevalence by asking "How often have you experienced the above in a church or Christian group setting?" and providing participants a Liker scale of five response categories: (1) Never, (2) Once or twice, (3) Sometimes, (4) Often, and (5) All the time. The large number of prompts in this first section were presented in a randomized order so that all prompts would receive responses by approximately the same number of participants even if many participants did not complete all of the prompts in this section.

The second section, Internal States, included 14 prompts about personal feelings resulting from the abusive experiences described in the first section. Prompts in this section measured prevalence by asking "At any point, how often have you experienced the above as a result of negative religious experiences?" Participants were provided the same 5-point Likert scale of response categories as in the first section: (1) Never, (2) Once or twice, (3) Sometimes, (4) Often, and (5) All the time.

## Data Analysis

In their initial validation of the SHAS, @KochEdstrom2022 examined the dimensionality of the 66 items. The authors used exploratory factor analysis (EFA) to determine the factor structure of the items. In these EFA analyses, the items loaded onto six inter-related factors of eigenvalues of at least 1. This enabled the authors to distill the item pool from 66 to 27 items and to identify several meaningful subscales for potential future use by clinicians and researchers.

For this study, we focused on the commonality of the items in order to use item response theory to establish a single interval scale of spiritual abuse. Item response theory models make two assumptions: (1) a single latent trait explains responses to items (unidimensionality) and (2) after controlling for this latent trait, items are weakly correlated (local independence) [@EmbretsonReise2000; @ReiseWaller2009; @ReiseBonifayHaviland2013]. The SHAS items were multidimensional by design. The construct of spiritual harm and abuse is not conceptually narrow, and to cover the breadth of this construct, @KochEdstrom2022 wrote two distinct item sets. However, a unidimensional IRT model can be appropriately fit to multidimensional data [@ReiseMooreHaviland2013]. In this study we hypothesized a general factor of spiritual abuse as the primary cause of responses to the full set of 66 SHAS items. We therefore sought evidence of unidimensionality and local independence in order to calibrate the items and participants to a single IRT scale.

We began by examining classical item statistics to identify poorly functioning items based on extreme values of skew and kurtosis and low item-total correlations. Then we conducted several analyses of dimensionality in search of sufficient evidence of unidimensionality and local independence. This included principal components analysis to compare the eigenvalues of the largest and second largest components. Like factor analysis, component analysis attempts to summarize the common variance in items by identifying a smaller set of latent sources of covariation. Principal components analysis differs from factor analysis by treating all of the common variance among the items as the total variance to be explained \[verify this\]. We estimated a unidimensional Rasch model and calculated the proportion of variance in the data it explained. This we followed with a Principal Components Analysis of Residuals (PCAR) to gauge the importance of components in the item residuals, and with a similar statistic, Q3 [@Yen1984], to further inspect the correlations among item residuals.

We estimated a Rating Scale model [@Andrich1978] to the SHAS items. We began by examining plots of the category characteristic curves of the items to visualize step parameters. Then we turned to item severity parameters and item fit statistics to inspect the technical quality of the items. We examined an item-person map to understand the fit of the items to the participants. We concluded by assessing the fit of the model to the data.

Finally, we conducted differential item functioning (DIF) analysis of the items to examine item bias by gender, and age, and race. \[We applied logistic ordinal regression with IRT scoring. We used the Chi-squared likelihood-ratio statistic as the initial DIF detection criteria (alpha \< 0.01), and a cut-off of McFadden pseudo R2Δ ≥ 0.02 in model comparisons to determine substantial DIF, a reasonable threshold used in the development of self-reported health outcomes.\]

We conducted all analyses in **R** [@R-base]. We used the **psych** [@R-psych] and **eRm** [@R-eRm] packages for analyses of dimensionality, the **mirt** [@R-mirt] and **TAM** [@R-TAM] packages for Rating Scale analyses, and the **lordif** package for DIF analyses.
